Policy Engine
-------------

The module provides a defined resource type that generates a Facter plugin for
policy tests. Each Facter run, the plugin executes a specified script,
written in any language, and compares the execution result to the expected
output. If the expectation matches, the test passes. If not, it fails. The test
result is added as a structured fact. 

The facts can be used as part of a continuous delivery pipeline to ensure
individual node configurations meet relevant policy requirements before
configurations are deployed to production. The facts can be queried from
PuppetDB for continuous policy monitoring.

The tests follow the [rspec](http://rspec.info/) model of declaring what you
want to do and what the expected result is. If the result doesn't match
the expectation, the test fails.

Each test result is a structured value in a standard format. The output format
is as follows:

**If the test passed**

`{'result' => 'pass', 'tags' => ['policy_engine','tag1','tag2']}`

**If the test fails**

`{'result' => 'fail', 'tags' => ['policy_engine','tag1','tag2'], 'expected_output' => [], 'is' => ['example','output']}`

##Declaring Policy Tests 
Tests can be written in any language the system they run on supports. The code
that performs the test can range from a single shell command to a script file.
The user can specify an interpreter to use to run the code (defaults to
/bin/sh).

To validate a test passes or fails, an expectation can be specified. An expectation can be the following:
* Stdout output. The output can be parsed as a string, JSON, or YAML
* Stderr output. The output is parsed as a string
* Exit code. The exit code of the script execution

**Execute a command and expect no output**
```
policy_engine::test { 'name_of_test':
  script          => 'single command to run',
  expected_output => '',
}
```

**Execute a python script generated by an ERB and expect an empty array in JSON**
```
policy_engine::test { 'another_test':
  script          => template('my_module/test.py.erb'),
  expected_output => [],
  interpreter     => 'python',
  output_format   => 'json',
}
```

**Execute a ruby script from a module and expect an empty array in YAML**
```
policy_engine::test { 'ruby_test':
  source          => 'puppet:///modules/my_module/thing',
  expected_output => [],
  interpreter     => 'ruby',
  output_format   => 'yaml',
}
```

##Reference

###Classes

####Public classes
* `policy_engine`: Configures Policy Engine testing framework

###Parameters

####policy_engine

#####`test_dir`

The directory where the test metadata and execution scripts will be kept

###Defined Types
* `policy_engine::test`: A Policy Engine test

####policy_engine::test

#####Parameters
* `ensure`: valid values are *present* or *absent*. Defaults to *present*
* `source`: The source of a script.  Follows same values as the [file type](https://docs.puppetlabs.com/references/latest/type.html#file-attribute-source)
* `script`: A script to run in text format.  This is similar to the content parameter for the [file type](https://docs.puppetlabs.com/references/latest/type.html#file-attribute-content)
* `interpreter`: The interpreter on the system to run.  Defaults to */bin/sh*
* `output_format`: What format the stdout is in from the execution script. Valid values are *string*, *json*, and *yaml*.  Defaults to *string*
* `expected_output`: What the expected stdout output is.
* `expected_exit_code`: What the expected exit code of the execution script is.  If specified, this parameter has precedence over the expected_output parameter.
* `tags`: Arbitrary tags for the policy test. Every test is automatically tagged with *policy_engine*
